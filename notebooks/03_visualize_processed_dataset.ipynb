{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Visualization — Explore Processed Whole-Slide Data\n",
    "\n",
    "**Purpose:**  \n",
    "This notebook visualizes the processed outputs generated in  \n",
    "`02_generate_processed_dataset.ipynb`.  \n",
    "It allows interactive exploration of whole-slide images, cell-type maps,  \n",
    "and overlays for validation and quality control.\n",
    "\n",
    "---\n",
    "\n",
    "### What you can do here\n",
    "1. Load instance (`inst_map`) and type (`type_map`) masks.\n",
    "2. Visualize them alongside the original H&E images.\n",
    "3. Inspect color-coded overlays to confirm annotation accuracy.\n",
    "4. Interactively switch between slides using a dropdown or slider.\n",
    "\n",
    "---\n",
    "\n",
    "### Folder Dependencies\n",
    "| Folder | Description |\n",
    "|:--|:--|\n",
    "| `/ProcessedDataset/v1_40x_area20/whole_slide/inst_maps` | Instance label maps |\n",
    "| `/ProcessedDataset/v1_40x_area20/whole_slide/type_maps` | Cell-type maps |\n",
    "| `/TrainingData/TrainingImages_and_Annotations` | Original images (.svs) |\n",
    "| `/ProcessedDataset/v1_40x_area20/_meta/class_map.json` | Cell-type color/ID mapping |\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "- [Step 1 — Setup and Imports](#step1)\n",
    "- [Step 2 — Load Class Map and Available Slides](#step2)\n",
    "- [Step 3 — Interactive Visualization](#step3)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step1\"></a>\n",
    "## Step 1 — Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists:     1  →  /projectnb/ec500kb/projects/Fall_2025_Projects/Project_2/AI-guided-whole-slide-imaging-analysis/Datasets/BU_course_data/TrainingData/TrainingImages_and_Annotations\n",
      "Exists:     1  →  /projectnb/ec500kb/projects/Fall_2025_Projects/Project_2/AI-guided-whole-slide-imaging-analysis/ProcessedDataset/v1_40x_area20\n",
      "Exists:     1  →  /projectnb/ec500kb/projects/Fall_2025_Projects/Project_2/AI-guided-whole-slide-imaging-analysis/ProcessedDataset/v1_40x_area20/whole_slide/type_maps\n",
      "Exists:     1  →  /projectnb/ec500kb/projects/Fall_2025_Projects/Project_2/AI-guided-whole-slide-imaging-analysis/ProcessedDataset/v1_40x_area20/whole_slide/inst_maps\n",
      "Exists:     1  →  /projectnb/ec500kb/projects/Fall_2025_Projects/Project_2/AI-guided-whole-slide-imaging-analysis/ProcessedDataset/v1_40x_area20/_meta\n"
     ]
    }
   ],
   "source": [
    "# Paths, imports, and basic checks\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional dependencies (handled gracefully if missing)\n",
    "try:\n",
    "    from openslide import OpenSlide\n",
    "except Exception as e:\n",
    "    OpenSlide = None\n",
    "    print(\"OpenSlide not available:\", e)\n",
    "\n",
    "# --- Project paths ---\n",
    "PROJECT_ROOT = Path(\"/projectnb/ec500kb/projects/Fall_2025_Projects/Project_2/AI-guided-whole-slide-imaging-analysis\")\n",
    "\n",
    "RAW_IMG_ROOT = PROJECT_ROOT / \"Datasets/BU_course_data/TrainingData/TrainingImages_and_Annotations\"\n",
    "PROC_ROOT    = PROJECT_ROOT / \"ProcessedDataset/v1_40x_area20\"\n",
    "TYPE_DIR     = PROC_ROOT / \"whole_slide/type_maps\"\n",
    "INST_DIR     = PROC_ROOT / \"whole_slide/inst_maps\"\n",
    "META_DIR     = PROC_ROOT / \"_meta\"\n",
    "\n",
    "# --- Sanity checks ---\n",
    "for p in [RAW_IMG_ROOT, PROC_ROOT, TYPE_DIR, INST_DIR, META_DIR]:\n",
    "    print(f\"Exists: {p.exists():5}  →  {p}\")\n",
    "\n",
    "# Matplotlib defaults\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "plt.rcParams[\"axes.grid\"] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "\n",
    "## Step 2 — Load Class Map and Discover Available Slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class map (id → name): {0: 'background', 1: 'epithelial', 2: 'lymphocyte', 3: 'macrophage', 4: 'neutrophil'}\n",
      "Slides available for visualization: 209\n",
      "Sample: ['TCGA-55-1594-01Z-00-DX1_001', 'TCGA-55-1594-01Z-00-DX1_002', 'TCGA-55-1594-01Z-00-DX1_003', 'TCGA-55-1594-01Z-00-DX1_004', 'TCGA-55-1594-01Z-00-DX1_005']\n",
      "Prepared color LUT for 4 classes (plus background).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/380494.1.ood/ipykernel_4091495/3905602792.py:26: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap(\"tab10\", n_classes + 1)\n"
     ]
    }
   ],
   "source": [
    "# Load class map and list processed slides\n",
    "\n",
    "# Load class_map.json produced in 02_generate_processed_dataset\n",
    "with open(META_DIR / \"class_map.json\", \"r\") as f:\n",
    "    class_map = json.load(f)\n",
    "\n",
    "# Normalize to int->str and str->int helpers\n",
    "id_to_name = {int(k): v for k, v in class_map.items()}\n",
    "name_to_id = {v: int(k) for k, v in id_to_name.items()}\n",
    "\n",
    "print(\"Class map (id → name):\", id_to_name)\n",
    "\n",
    "# Collect slide basenames from type_maps\n",
    "slide_names = sorted({p.stem.replace(\"_type\", \"\") for p in TYPE_DIR.glob(\"*_type.npy\")})\n",
    "print(f\"Slides available for visualization: {len(slide_names)}\")\n",
    "if slide_names[:5]:\n",
    "    print(\"Sample:\", slide_names[:5])\n",
    "\n",
    "# Simple utility: build a color look-up table for categorical masks\n",
    "def categorical_colormap(n_classes: int):\n",
    "    \"\"\"\n",
    "    Returns an (n_classes+1, 3) float array in [0,1] for indexing by class id.\n",
    "    Index 0 is background. Uses tab10/tab20 depending on class count.\n",
    "    \"\"\"\n",
    "    if n_classes <= 10:\n",
    "        cmap = plt.cm.get_cmap(\"tab10\", n_classes + 1)\n",
    "    else:\n",
    "        cmap = plt.cm.get_cmap(\"tab20\", n_classes + 1)\n",
    "    lut = cmap(np.arange(n_classes + 1))[:, :3]  # drop alpha\n",
    "    return lut\n",
    "\n",
    "# Prepare LUT based on max class id present in class_map\n",
    "max_cls_id = max(id_to_name.keys())\n",
    "LUT = categorical_colormap(max_cls_id)\n",
    "\n",
    "print(f\"Prepared color LUT for {max_cls_id} classes (plus background).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step3\"></a>\n",
    "\n",
    "## Step 3 — Interactive Visualization (RGB • type_map • overlay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3714ec1a034cfa9f1cd83aa1664031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Slide:', layout=Layout(width='70%'), options=('TCGA-55-1594-01Z-00-DX1_00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac993bf87f294cbba8e9d921ce9ced5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# --- Color-blind friendly LUT ---\n",
    "def categorical_colormap(n_classes: int):\n",
    "    \"\"\"\n",
    "    Returns an (n_classes+1, 3) float array in [0,1] for indexing by class id.\n",
    "    Uses color-blind–safe 'Set2' or 'tab20' palette.\n",
    "    \"\"\"\n",
    "    import matplotlib\n",
    "    get_cmap = matplotlib.colormaps.get_cmap\n",
    "    cmap = get_cmap(\"Set2\" if n_classes <= 8 else \"tab20\")\n",
    "    lut = cmap(np.linspace(0, 1, n_classes + 1))[:, :3]\n",
    "    return lut\n",
    "\n",
    "# Rebuild LUT\n",
    "max_cls_id = max(id_to_name.keys())\n",
    "LUT = categorical_colormap(max_cls_id)\n",
    "\n",
    "def find_image_path(slide_name: str) -> Path | None:\n",
    "    \"\"\"\n",
    "    Locate the corresponding .svs (preferred) or .tif for a slide basename\n",
    "    by searching patient subfolders under RAW_IMG_ROOT.\n",
    "    \"\"\"\n",
    "    for patient_dir in sorted(RAW_IMG_ROOT.iterdir()):\n",
    "        if not patient_dir.is_dir():\n",
    "            continue\n",
    "        svs_candidate = patient_dir / f\"{slide_name}.svs\"\n",
    "        if svs_candidate.exists():\n",
    "            return svs_candidate\n",
    "        tif_candidate = patient_dir / f\"{slide_name}.tif\"\n",
    "        if tif_candidate.exists():\n",
    "            return tif_candidate\n",
    "    return None\n",
    "\n",
    "def load_rgb_image(img_path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load RGB from .svs/.tif. Prefer OpenSlide when available; otherwise fallback to cv2 for .tif.\n",
    "    \"\"\"\n",
    "    if img_path.suffix.lower() == \".svs\":\n",
    "        if OpenSlide is None:\n",
    "            raise RuntimeError(\"OpenSlide is required to read .svs files.\")\n",
    "        with OpenSlide(str(img_path)) as slide:\n",
    "            w, h = slide.level_dimensions[0]\n",
    "            rgb = np.array(slide.read_region((0, 0), 0, (w, h)))[:, :, :3]\n",
    "        return rgb\n",
    "    else:\n",
    "        # .tif fallback\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            raise RuntimeError(f\"Failed to read image: {img_path}\")\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return rgb\n",
    "\n",
    "def visualize_slide(slide_name: str, alpha: float = 0.45):\n",
    "    type_path = TYPE_DIR / f\"{slide_name}_type.npy\"\n",
    "    inst_path = INST_DIR / f\"{slide_name}_inst.npy\"\n",
    "\n",
    "    if not type_path.exists() or not inst_path.exists():\n",
    "        print(f\"Missing maps for {slide_name}\")\n",
    "        return\n",
    "\n",
    "    # Load maps\n",
    "    type_map = np.load(type_path)\n",
    "    inst_map = np.load(inst_path)\n",
    "\n",
    "    # Load original image\n",
    "    img_path = find_image_path(slide_name)\n",
    "    if img_path is None:\n",
    "        print(f\"No .svs/.tif found for {slide_name}\")\n",
    "        return\n",
    "    rgb = load_rgb_image(img_path)\n",
    "\n",
    "    # Remove background for overlay (keep as mask)\n",
    "    mask = type_map > 0\n",
    "\n",
    "    # Build overlay from LUT\n",
    "    tm_clipped = np.clip(type_map, 0, LUT.shape[0] - 1).astype(int)\n",
    "    color_mask = LUT[tm_clipped]\n",
    "    # zero out background\n",
    "    color_mask[~mask] = 0.0\n",
    "\n",
    "    # Strengthen color visibility (gamma + scaling)\n",
    "    color_mask = np.power(color_mask, 0.7)  # slightly more vivid\n",
    "    overlay = rgb / 255.0\n",
    "    overlay[mask] = (1 - alpha) * overlay[mask] + alpha * color_mask[mask]\n",
    "\n",
    "    # --- Plot ---\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "    axes[0].imshow(rgb)\n",
    "    axes[0].set_title(\"H&E (RGB)\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    im1 = axes[1].imshow(type_map, cmap=\"Set2\", vmin=0, vmax=max_cls_id)\n",
    "    axes[1].set_title(\"Type Map (IDs)\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(\"Overlay (No Background)\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Legend (only classes present) ---\n",
    "    present = sorted(np.unique(type_map[type_map > 0]))\n",
    "    legend_patches = [\n",
    "        Patch(color=LUT[i], label=f\"{i}: {id_to_name.get(i, 'unknown')}\")\n",
    "        for i in present\n",
    "    ]\n",
    "    plt.figure(figsize=(6, 0.6 + 0.3 * len(present)))\n",
    "    plt.legend(\n",
    "        handles=legend_patches,\n",
    "        title=\"Cell Types\",\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(0, 0.5),\n",
    "        frameon=False,\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Classes present:\", \", \".join(id_to_name[i] for i in present))\n",
    "\n",
    "# UI\n",
    "dropdown = widgets.Dropdown(options=slide_names, description=\"Slide:\", layout=widgets.Layout(width=\"70%\"))\n",
    "ui = widgets.VBox([dropdown])\n",
    "out = widgets.interactive_output(visualize_slide, {\"slide_name\": dropdown})\n",
    "display(ui, out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellvit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
